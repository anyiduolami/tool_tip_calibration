"""
Interactive Tool Tip Tracker
å®ç°æ‘„åƒå¤´æ‹ç…§ã€å›¾ç‰‡é€‰æ‹©ã€ç‚¹æ£€æµ‹å’Œå°–ç«¯ä½ç½®æ±‚è§£çš„äº¤äº’å¼ç¨‹åº
"""

import cv2
import numpy as np
import os
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
from PIL import Image, ImageTk
import threading
import time

class InteractiveTipTracker:
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("Interactive Tool Tip Tracker")
        self.root.geometry("1200x800")
        
        # åˆå§‹åŒ–å˜é‡
        self.camera = None
        self.is_capturing = False
        self.captured_images = []
        self.detected_points = None
        self.tip_position = None
        self.current_frame = None

        # ä¸¤ç‚¹æµ‹è·ç›¸å…³å˜é‡
        self.start_image = None
        self.end_image = None
        self.start_points = []
        self.end_points = []
        self.start_tip_position = None
        self.end_tip_position = None
        self.max_capture_count = 2  # æœ€å¤šæ‹æ‘„2å¼ ç…§ç‰‡
        self.capture_count = 0  # å½“å‰æ‹æ‘„è®¡æ•°
        self.show_dual_images = False  # æ˜¯å¦æ˜¾ç¤ºå¹¶æ’å›¾åƒ
        
        # åŠ è½½æ ‡å®šæ•°æ®
        self.load_calibration_data()
        
        # åˆå§‹åŒ–æ£€æµ‹å‚æ•°ï¼ˆå¯ä»¥è‡ªå®šä¹‰è°ƒæ•´ï¼‰
        self.detection_params = {
            # Blobæ£€æµ‹å‚æ•°
            'min_threshold': 50,
            'max_threshold': 200,
            'threshold_step': 10,
            'min_area': 100,
            'max_area': 5000,
            'min_circularity': 0.7,
            'max_circularity': 1.0,
            'min_convexity': 0.4,
            'max_convexity': 1.0,
            'min_inertia_ratio': 0.4,
            'max_inertia_ratio': 1.0,

            # å›¾åƒé¢„å¤„ç†å‚æ•°
            'gaussian_blur_size': 5,
            'morphology_kernel_size': 3,
            'clahe_clip_limit': 2.0,
            'clahe_tile_size': 8,

            # é¢œè‰²æ£€æµ‹å‚æ•°
            'blob_color': 0,  # 0=æš—è‰²blob, 255=äº®è‰²blob
        }
        
        # åˆ›å»ºUIç•Œé¢
        self.create_ui()
        
        # åˆ›å»ºimagesæ–‡ä»¶å¤¹
        os.makedirs('images', exist_ok=True)
        
    def load_calibration_data(self):
        """åŠ è½½ç›¸æœºæ ‡å®šå’Œå·¥å…·æ ‡å®šæ•°æ®"""
        try:
            # åŠ è½½ç›¸æœºæ ‡å®šæ•°æ®
            calib_data = np.load('calibration/camera_calibration.npz')
            self.camera_matrix = calib_data['camera_matrix']
            self.dist_coeffs = calib_data['dist_coeffs']
            print("âœ… ç›¸æœºæ ‡å®šæ•°æ®åŠ è½½æˆåŠŸ")
            
            # åŠ è½½å·¥å…·æ ‡å®šç»“æœ
            tool_data = np.load('tool_tip_calibration_results.npz')
            self.tip_world = tool_data['tip_world']
            self.tip_tool = tool_data['tip_tool']
            print("âœ… å·¥å…·æ ‡å®šæ•°æ®åŠ è½½æˆåŠŸ")
            print(f"   Tip_w: {self.tip_world}")
            print(f"   Tip_t: {self.tip_tool}")
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ ‡å®šæ•°æ®å¤±è´¥: {e}")
            messagebox.showerror("é”™è¯¯", f"åŠ è½½æ ‡å®šæ•°æ®å¤±è´¥: {e}")
            
    def create_ui(self):
        """åˆ›å»ºç”¨æˆ·ç•Œé¢"""
        # è®¾ç½®æ›´å¤§çš„çª—å£å°ºå¯¸
        self.root.geometry("1400x900")

        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root, padding="15")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # é…ç½®ç½‘æ ¼æƒé‡ - è°ƒæ•´æ¯”ä¾‹è®©å›¾åƒæ˜¾ç¤ºåŒºåŸŸæ›´å¤§
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(0, weight=0)  # å·¦ä¾§æ§åˆ¶é¢æ¿å›ºå®šå®½åº¦
        main_frame.columnconfigure(1, weight=1)  # å³ä¾§å›¾åƒæ˜¾ç¤ºåŒºåŸŸè‡ªé€‚åº”
        main_frame.rowconfigure(0, weight=1)

        # å·¦ä¾§æ§åˆ¶é¢æ¿ - è°ƒæ•´å®½åº¦å’Œæ ·å¼
        control_frame = ttk.LabelFrame(main_frame, text="ğŸ›ï¸ æ§åˆ¶é¢æ¿", padding="15")
        control_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=(0, 15))
        control_frame.configure(width=350)  # å›ºå®šå®½åº¦
        
        # æ‘„åƒå¤´æ§åˆ¶ - ç¾åŒ–æ ·å¼
        camera_frame = ttk.LabelFrame(control_frame, text="ğŸ“· æ‘„åƒå¤´æ§åˆ¶", padding="10")
        camera_frame.pack(fill=tk.X, pady=(0, 15))

        # æ‘„åƒå¤´ä¿¡æ¯æ˜¾ç¤º
        camera_info_frame = ttk.Frame(camera_frame)
        camera_info_frame.pack(fill=tk.X, pady=(0, 8))

        info_label = ttk.Label(camera_info_frame, text="ğŸ“¹ ä½¿ç”¨å¤–æ¥æ‘„åƒå¤´ (ç´¢å¼•: 1)",
                              font=("Arial", 9), foreground="gray")
        info_label.pack()

        # æŒ‰é’®æ ·å¼ä¼˜åŒ–
        self.start_camera_btn = ttk.Button(camera_frame, text="ğŸŸ¢ å¯åŠ¨æ‘„åƒå¤´", command=self.start_camera)
        self.start_camera_btn.pack(fill=tk.X, pady=3, ipady=5)

        self.stop_camera_btn = ttk.Button(camera_frame, text="ğŸ”´ åœæ­¢æ‘„åƒå¤´", command=self.stop_camera, state=tk.DISABLED)
        self.stop_camera_btn.pack(fill=tk.X, pady=3, ipady=5)

        # æ‹ç…§æŒ‰é’®ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
        self.capture_btn = ttk.Button(camera_frame, text="ğŸ“¸ æ‹ç…§ (ç©ºæ ¼é”®)", command=self.manual_capture, state=tk.DISABLED)
        self.capture_btn.pack(fill=tk.X, pady=3, ipady=5)



        # æ“ä½œè¯´æ˜ - ç®€åŒ–å¹¶ç¾åŒ–
        instruction_frame = ttk.LabelFrame(control_frame, text="ğŸ“‹ æ“ä½œè¯´æ˜", padding="10")
        instruction_frame.pack(fill=tk.X, pady=(0, 15))

        instructions = [
            "1ï¸âƒ£ å¯åŠ¨æ‘„åƒå¤´å¼€å§‹æ‹æ‘„",
            "2ï¸âƒ£ ç©ºæ ¼é”®æ‹ç…§(2å¼ )",
            "3ï¸âƒ£ Enteré”®æ˜¾ç¤ºä¸¤å¼ å›¾ç‰‡",
            "4ï¸âƒ£ æ£€æµ‹æ ‡è®°ç‚¹å¹¶è®¡ç®—è·ç¦»"
        ]

        for instruction in instructions:
            label = ttk.Label(instruction_frame, text=instruction, font=("Arial", 9))
            label.pack(anchor=tk.W, pady=1)

        # å›¾ç‰‡å¤„ç† - ç¾åŒ–æŒ‰é’®
        image_frame = ttk.LabelFrame(control_frame, text="ğŸ–¼ï¸ å›¾ç‰‡å¤„ç†", padding="10")
        image_frame.pack(fill=tk.X, pady=(0, 15))

        self.detect_points_btn = ttk.Button(image_frame, text="ğŸ¯ æ£€æµ‹æ ‡è®°ç‚¹", command=self.detect_points, state=tk.DISABLED)
        self.detect_points_btn.pack(fill=tk.X, pady=3, ipady=5)

        self.calculate_tip_btn = ttk.Button(image_frame, text="ï¿½ è®¡ç®—ä¸¤ç‚¹è·ç¦»", command=self.calculate_tip_position, state=tk.DISABLED)
        self.calculate_tip_btn.pack(fill=tk.X, pady=3, ipady=5)

        # ç»“æœæ˜¾ç¤º - æ‰©å¤§æ˜¾ç¤ºåŒºåŸŸ
        result_frame = ttk.LabelFrame(control_frame, text="ğŸ“Š ç»“æœæ˜¾ç¤º", padding="10")
        result_frame.pack(fill=tk.BOTH, expand=True, pady=(0, 15))

        # åˆ›å»ºæ»šåŠ¨æ–‡æœ¬æ¡†
        text_frame = ttk.Frame(result_frame)
        text_frame.pack(fill=tk.BOTH, expand=True)

        # æ–‡æœ¬æ¡†å’Œæ»šåŠ¨æ¡
        self.result_text = tk.Text(text_frame, height=20, width=40,
                                  font=("Consolas", 9), wrap=tk.WORD,
                                  bg="#f8f9fa", fg="#212529",
                                  selectbackground="#007bff",
                                  relief=tk.FLAT, borderwidth=1)

        scrollbar = ttk.Scrollbar(text_frame, orient=tk.VERTICAL, command=self.result_text.yview)
        self.result_text.configure(yscrollcommand=scrollbar.set)

        self.result_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

        # æ·»åŠ æ¸…ç©ºæŒ‰é’®
        clear_btn = ttk.Button(result_frame, text="ğŸ—‘ï¸ æ¸…ç©ºç»“æœ", command=self.clear_results)
        clear_btn.pack(fill=tk.X, pady=(5, 0))
        
        # å³ä¾§æ˜¾ç¤ºåŒºåŸŸ - ä¼˜åŒ–å¸ƒå±€
        display_frame = ttk.LabelFrame(main_frame, text="ğŸ–¼ï¸ å›¾åƒæ˜¾ç¤º", padding="15")
        display_frame.grid(row=0, column=1, sticky=(tk.W, tk.E, tk.N, tk.S))
        display_frame.columnconfigure(0, weight=1)
        display_frame.rowconfigure(0, weight=1)

        # å›¾åƒæ˜¾ç¤ºæ ‡ç­¾ - æ·»åŠ è¾¹æ¡†å’ŒèƒŒæ™¯
        self.image_label = ttk.Label(display_frame, text="ğŸ“· å›¾åƒå°†åœ¨è¿™é‡Œæ˜¾ç¤º\n\nè¯·é€‰æ‹©å›¾ç‰‡æˆ–å¯åŠ¨æ‘„åƒå¤´å¼€å§‹",
                                    font=("Arial", 12), foreground="gray",
                                    anchor=tk.CENTER, justify=tk.CENTER)
        self.image_label.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=10, pady=10)

        # çŠ¶æ€æ  - ç¾åŒ–æ ·å¼
        self.status_var = tk.StringVar()
        self.status_var.set("ğŸŸ¢ ç³»ç»Ÿå°±ç»ª")
        status_bar = ttk.Label(main_frame, textvariable=self.status_var,
                              relief=tk.SUNKEN, font=("Arial", 9),
                              background="#e9ecef", foreground="#495057")
        status_bar.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(15, 0))

        # ç»‘å®šé”®ç›˜äº‹ä»¶
        self.root.bind('<KeyPress>', self.on_key_press)
        self.root.focus_set()  # ç¡®ä¿çª—å£å¯ä»¥æ¥æ”¶é”®ç›˜äº‹ä»¶

    def clear_results(self):
        """æ¸…ç©ºç»“æœæ˜¾ç¤º"""
        self.result_text.delete(1.0, tk.END)
        self.status_var.set("ğŸ—‘ï¸ ç»“æœå·²æ¸…ç©º")
        




    def on_key_press(self, event):
        """å¤„ç†é”®ç›˜æŒ‰é”®äº‹ä»¶"""
        if self.is_capturing and self.current_frame is not None:
            if event.keysym == 'space':  # ç©ºæ ¼é”®æ‹ç…§
                self.capture_image(self.current_frame)
            elif event.keysym == 'Return':  # Enteré”®
                if self.capture_count == 2:
                    # æ‹æ‘„å®Œä¸¤å¼ ç…§ç‰‡åï¼ŒæŒ‰Enteræ˜¾ç¤ºå¹¶æ’å›¾åƒ
                    self.show_captured_images()
                else:
                    # å¦åˆ™åœæ­¢æ‘„åƒå¤´
                    self.stop_camera()

    def show_captured_images(self):
        """æ˜¾ç¤ºæ‹æ‘„çš„ä¸¤å¼ å›¾ç‰‡å¹¶åœæ­¢æ‘„åƒå¤´"""
        if self.capture_count == 2 and self.start_image and self.end_image:
            # è®¾ç½®æ ‡å¿—é˜»æ­¢æ‘„åƒå¤´è¦†ç›–æ˜¾ç¤º
            self.show_dual_images = True

            # åœæ­¢æ‘„åƒå¤´
            self.stop_camera()

            # å¯ç”¨æ£€æµ‹æŒ‰é’®
            self.detect_points_btn.config(state=tk.NORMAL)

            # æ˜¾ç¤ºå¹¶æ’å›¾åƒ
            self.display_dual_images()

            self.update_result_text("ğŸ“· å·²æ˜¾ç¤ºæ‹æ‘„çš„ä¸¤å¼ å›¾ç‰‡\n")
            self.status_var.set("âœ… å›¾ç‰‡å·²æ˜¾ç¤ºï¼Œå¯ä»¥å¼€å§‹æ£€æµ‹æ ‡è®°ç‚¹")
        else:
            self.update_result_text("âš ï¸ è¯·å…ˆæ‹æ‘„ä¸¤å¼ ç…§ç‰‡\n")

    def manual_capture(self):
        """æ‰‹åŠ¨æ‹ç…§ï¼ˆæŒ‰é’®è§¦å‘ï¼‰"""
        if self.is_capturing and self.current_frame is not None:
            self.capture_image(self.current_frame)

    def start_camera(self):
        """å¯åŠ¨å¤–æ¥æ‘„åƒå¤´ï¼ˆç´¢å¼•1ï¼‰"""
        try:
            # ç›´æ¥ä½¿ç”¨ç´¢å¼•1ä½œä¸ºå¤–æ¥æ‘„åƒå¤´
            camera_index = 0
            self.status_var.set("æ­£åœ¨å¯åŠ¨å¤–æ¥æ‘„åƒå¤´...")

            self.camera = cv2.VideoCapture(camera_index)
            if not self.camera.isOpened():
                raise Exception(f"æ— æ³•æ‰“å¼€å¤–æ¥æ‘„åƒå¤´ (ç´¢å¼•: {camera_index})ï¼Œè¯·ç¡®ä¿å¤–æ¥æ‘„åƒå¤´å·²è¿æ¥")

            # è®¾ç½®æ‘„åƒå¤´å‚æ•°ä»¥è·å¾—æ›´å¥½çš„å›¾åƒè´¨é‡
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
            self.camera.set(cv2.CAP_PROP_FPS, 30)

            # è·å–å®é™…è®¾ç½®çš„å‚æ•°
            width = int(self.camera.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(self.camera.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = int(self.camera.get(cv2.CAP_PROP_FPS))

            # é‡ç½®æ‹æ‘„è®¡æ•°å’Œå›¾åƒ
            self.capture_count = 0
            self.captured_images = []
            self.start_image = None
            self.end_image = None
            self.start_points = []
            self.end_points = []
            self.start_tip_position = None
            self.end_tip_position = None
            self.show_dual_images = False  # é‡ç½®æ˜¾ç¤ºæ ‡å¿—

            self.is_capturing = True
            self.start_camera_btn.config(state=tk.DISABLED)
            self.stop_camera_btn.config(state=tk.NORMAL)
            self.capture_btn.config(state=tk.NORMAL)
            self.detect_points_btn.config(state=tk.DISABLED)

            # å¯åŠ¨æ‘„åƒå¤´çº¿ç¨‹
            self.camera_thread = threading.Thread(target=self.camera_loop)
            self.camera_thread.daemon = True
            self.camera_thread.start()

            self.status_var.set(f"å¤–æ¥æ‘„åƒå¤´å·²å¯åŠ¨ (ç´¢å¼•:{camera_index}, {width}x{height}@{fps}fps) - æŒ‰ç©ºæ ¼é”®æ‹ç…§ï¼ŒæŒ‰Enteré”®ç»“æŸ")
            self.update_result_text(f"âœ… æˆåŠŸå¯åŠ¨å¤–æ¥æ‘„åƒå¤´ (ç´¢å¼•: {camera_index})\n")
            self.update_result_text(f"   åˆ†è¾¨ç‡: {width}x{height}, å¸§ç‡: {fps}fps\n")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"å¯åŠ¨å¤–æ¥æ‘„åƒå¤´å¤±è´¥: {e}")
            self.status_var.set("å¤–æ¥æ‘„åƒå¤´å¯åŠ¨å¤±è´¥")
            
    def stop_camera(self):
        """åœæ­¢æ‘„åƒå¤´"""
        self.is_capturing = False
        if self.camera:
            self.camera.release()
            self.camera = None

        self.start_camera_btn.config(state=tk.NORMAL)
        self.stop_camera_btn.config(state=tk.DISABLED)
        self.capture_btn.config(state=tk.DISABLED)
        self.status_var.set(f"æ‘„åƒå¤´å·²åœæ­¢ - å…±æ‹æ‘„ {len(self.captured_images)} å¼ å›¾ç‰‡")
        
    def camera_loop(self):
        """æ‘„åƒå¤´å¾ªç¯"""
        while self.is_capturing and self.camera:
            ret, frame = self.camera.read()
            if ret:
                # å­˜å‚¨å½“å‰å¸§ç”¨äºæ‹ç…§
                self.current_frame = frame.copy()

                # åªæœ‰åœ¨ä¸éœ€è¦æ˜¾ç¤ºå¹¶æ’å›¾åƒæ—¶æ‰æ˜¾ç¤ºæ‘„åƒå¤´ç”»é¢
                if not self.show_dual_images:
                    # åœ¨ç”»é¢ä¸Šæ·»åŠ æ‹ç…§è®¡æ•°å­—å¹•
                    frame_with_overlay = self.add_capture_overlay(frame)
                    self.display_image(frame_with_overlay)

                # çŸ­æš‚å»¶æ—¶
                time.sleep(0.033)  # çº¦30fps
            else:
                break

    def add_capture_overlay(self, frame):
        """åœ¨æ‘„åƒå¤´ç”»é¢ä¸Šæ·»åŠ æ‹ç…§è®¡æ•°å­—å¹•"""
        overlay_frame = frame.copy()

        # è·å–ç”»é¢å°ºå¯¸
        _, width = overlay_frame.shape[:2]

        # åœ¨å³ä¸Šè§’æ˜¾ç¤ºæ‹ç…§è®¡æ•°
        count_text = f"{self.capture_count}/2"
        if self.capture_count < 2:
            color = (0, 255, 0)  # ç»¿è‰²
        else:
            color = (255, 0, 0)  # è“è‰²

        cv2.putText(overlay_frame, count_text, (width - 100, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 4)
        cv2.putText(overlay_frame, count_text, (width - 100, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)

        # åªæœ‰åœ¨æ‹æ‘„å®Œä¸¤å¼ ç…§ç‰‡åï¼Œåœ¨å·¦ä¸Šè§’æ˜¾ç¤ºEnteræç¤º
        if self.capture_count == 2:
            enter_text = "Press ENTER to view images"
            cv2.putText(overlay_frame, enter_text, (20, 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 3)
            cv2.putText(overlay_frame, enter_text, (20, 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)

        return overlay_frame
        
    def capture_image(self, frame):
        """æ‹æ‘„å›¾ç‰‡ - æœ€å¤šæ‹æ‘„2å¼ ç…§ç‰‡"""
        if self.capture_count >= self.max_capture_count:
            self.update_result_text("å·²è¾¾åˆ°æœ€å¤§æ‹æ‘„æ•°é‡(2å¼ )ï¼Œè¯·å…ˆå¤„ç†å½“å‰å›¾ç‰‡\n")
            return

        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"images/captured_{timestamp}.jpg"

        cv2.imwrite(filename, frame)
        self.captured_images.append(filename)
        self.capture_count += 1

        # æ ¹æ®æ‹æ‘„é¡ºåºä¿å­˜ä¸ºèµ·å§‹ç‚¹æˆ–ç»ˆç‚¹å›¾åƒ
        if self.capture_count == 1:
            self.start_image = filename
            self.update_result_text(f"ğŸ“ èµ·å§‹ç‚¹å›¾åƒ: {filename}\n")
            self.status_var.set("ğŸ“· å·²æ‹æ‘„èµ·å§‹ç‚¹ï¼Œè¯·æ‹æ‘„ç»ˆç‚¹")
        elif self.capture_count == 2:
            self.end_image = filename
            self.update_result_text(f"ğŸ¯ ç»ˆç‚¹å›¾åƒ: {filename}\n")
            self.status_var.set("âœ… å·²æ‹æ‘„ä¸¤å¼ å›¾ç‰‡ï¼ŒæŒ‰Enteré”®æŸ¥çœ‹å›¾åƒ")

            # ä¸è‡ªåŠ¨åœæ­¢æ‘„åƒå¤´ï¼Œç»§ç»­æ˜¾ç¤ºå¸¦å­—å¹•çš„ç”»é¢
            # ç”¨æˆ·éœ€è¦æŒ‰Enteré”®æ¥æŸ¥çœ‹å¹¶æ’å›¾åƒ

        self.update_result_text(f"å·²æ‹æ‘„ {self.capture_count}/{self.max_capture_count} å¼ å›¾ç‰‡\n")
        
    def display_image(self, cv_image):
        """åœ¨UIä¸­æ˜¾ç¤ºå›¾åƒ"""
        # è½¬æ¢é¢œè‰²ç©ºé—´
        rgb_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
        
        # è°ƒæ•´å›¾åƒå¤§å°ä»¥é€‚åº”æ˜¾ç¤ºåŒºåŸŸ
        height, width = rgb_image.shape[:2]
        max_width, max_height = 800, 600
        
        if width > max_width or height > max_height:
            scale = min(max_width/width, max_height/height)
            new_width = int(width * scale)
            new_height = int(height * scale)
            rgb_image = cv2.resize(rgb_image, (new_width, new_height))
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        pil_image = Image.fromarray(rgb_image)
        photo = ImageTk.PhotoImage(pil_image)
        
        # æ›´æ–°æ˜¾ç¤º
        self.image_label.configure(image=photo)
        self.image_label.image = photo  # ä¿æŒå¼•ç”¨

    def display_dual_images(self):
        """æ˜¾ç¤ºèµ·å§‹ç‚¹å’Œç»ˆç‚¹ä¸¤å¼ å›¾ç‰‡å¹¶æ’"""
        if not self.start_image or not self.end_image:
            return

        try:
            # è¯»å–ä¸¤å¼ å›¾ç‰‡
            start_img = cv2.imread(self.start_image)
            end_img = cv2.imread(self.end_image)

            if start_img is None or end_img is None:
                self.update_result_text("âŒ æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶\n")
                return

            # è½¬æ¢é¢œè‰²ç©ºé—´
            start_rgb = cv2.cvtColor(start_img, cv2.COLOR_BGR2RGB)
            end_rgb = cv2.cvtColor(end_img, cv2.COLOR_BGR2RGB)

            # è°ƒæ•´å›¾ç‰‡å¤§å°ä½¿å…¶ä¸€è‡´ - å¢å¤§æ˜¾ç¤ºå°ºå¯¸
            target_height = 400  # å¢åŠ é«˜åº¦
            start_h, start_w = start_rgb.shape[:2]
            end_h, end_w = end_rgb.shape[:2]

            # æŒ‰æ¯”ä¾‹ç¼©æ”¾
            start_scale = target_height / start_h
            end_scale = target_height / end_h

            start_new_w = int(start_w * start_scale)
            end_new_w = int(end_w * end_scale)

            start_resized = cv2.resize(start_rgb, (start_new_w, target_height))
            end_resized = cv2.resize(end_rgb, (end_new_w, target_height))

            # åˆ›å»ºå¹¶æ’å›¾åƒ
            gap = 30  # å¢åŠ é—´éš”
            total_width = start_new_w + end_new_w + gap
            combined_img = np.ones((target_height, total_width, 3), dtype=np.uint8) * 240  # æµ…ç°è‰²èƒŒæ™¯

            # æ”¾ç½®å›¾ç‰‡
            combined_img[:, :start_new_w] = start_resized
            combined_img[:, start_new_w+gap:start_new_w+gap+end_new_w] = end_resized

            # æ·»åŠ æ ‡ç­¾ - æ›´å¤§æ›´æ¸…æ™°çš„æ–‡å­—
            cv2.putText(combined_img, "START POINT", (10, 40),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)
            cv2.putText(combined_img, "END POINT", (start_new_w+gap+10, 40),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)

            # æ·»åŠ åˆ†éš”çº¿
            line_x = start_new_w + gap // 2
            cv2.line(combined_img, (line_x, 0), (line_x, target_height), (100, 100, 100), 2)

            # è½¬æ¢ä¸ºPILå›¾åƒå¹¶æ˜¾ç¤º
            pil_image = Image.fromarray(combined_img)
            photo = ImageTk.PhotoImage(pil_image)

            self.image_label.configure(image=photo)
            self.image_label.image = photo

            self.update_result_text("ğŸ“· å·²æ˜¾ç¤ºèµ·å§‹ç‚¹å’Œç»ˆç‚¹å›¾åƒ\n")

        except Exception as e:
            self.update_result_text(f"âŒ æ˜¾ç¤ºå›¾ç‰‡å¤±è´¥: {e}\n")
        

    def preprocess_image(self, image):
        """å›¾åƒé¢„å¤„ç†"""
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()

        # åº”ç”¨CLAHEå¢å¼ºå¯¹æ¯”åº¦
        clahe = cv2.createCLAHE(
            clipLimit=self.detection_params['clahe_clip_limit'],
            tileGridSize=(self.detection_params['clahe_tile_size'], self.detection_params['clahe_tile_size'])
        )
        enhanced = clahe.apply(gray)

        # é«˜æ–¯æ¨¡ç³Š
        if self.detection_params['gaussian_blur_size'] > 0:
            blurred = cv2.GaussianBlur(enhanced,
                                     (self.detection_params['gaussian_blur_size'],
                                      self.detection_params['gaussian_blur_size']), 0)
        else:
            blurred = enhanced

        # å½¢æ€å­¦æ“ä½œ
        kernel_size = self.detection_params['morphology_kernel_size']
        if kernel_size > 0:
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
            # å¼€è¿ç®—å»é™¤å™ªå£°
            processed = cv2.morphologyEx(blurred, cv2.MORPH_OPEN, kernel)
            # é—­è¿ç®—å¡«å……ç©ºæ´
            processed = cv2.morphologyEx(processed, cv2.MORPH_CLOSE, kernel)
        else:
            processed = blurred

        return processed

    def detect_blobs(self, image):
        """ä½¿ç”¨SimpleBlobDetectoræ£€æµ‹blobï¼Œå¹¶è®¡ç®—æ¯ä¸ªblobçš„åœ†åº¦"""
        # è®¾ç½®blobæ£€æµ‹å‚æ•°
        params = cv2.SimpleBlobDetector_Params()

        # é˜ˆå€¼å‚æ•°
        params.minThreshold = self.detection_params['min_threshold']
        params.maxThreshold = self.detection_params['max_threshold']
        params.thresholdStep = self.detection_params['threshold_step']

        # é¢ç§¯è¿‡æ»¤
        params.filterByArea = True
        params.minArea = self.detection_params['min_area']
        params.maxArea = self.detection_params['max_area']

        # åœ†å½¢åº¦è¿‡æ»¤
        params.filterByCircularity = True
        params.minCircularity = self.detection_params['min_circularity']
        params.maxCircularity = self.detection_params['max_circularity']

        # å‡¸æ€§è¿‡æ»¤
        params.filterByConvexity = True
        params.minConvexity = self.detection_params['min_convexity']
        params.maxConvexity = self.detection_params['max_convexity']

        # æƒ¯æ€§æ¯”è¿‡æ»¤
        params.filterByInertia = True
        params.minInertiaRatio = self.detection_params['min_inertia_ratio']
        params.maxInertiaRatio = self.detection_params['max_inertia_ratio']

        # é¢œè‰²è¿‡æ»¤
        params.filterByColor = True
        params.blobColor = self.detection_params['blob_color']

        # åˆ›å»ºæ£€æµ‹å™¨
        detector = cv2.SimpleBlobDetector_create(params)

        # æ£€æµ‹å…³é”®ç‚¹
        keypoints = detector.detect(image)

        # è®¡ç®—æ¯ä¸ªblobçš„è¯¦ç»†ç‰¹å¾ï¼ŒåŒ…æ‹¬åœ†åº¦
        points_with_features = []

        for kp in keypoints:
            # è·å–blobçš„åŸºæœ¬ä¿¡æ¯
            x, y = kp.pt
            size = kp.size

            # ä½¿ç”¨äºšåƒç´ ç²¾åº¦ä¼˜åŒ–ç‚¹ä½ç½®
            refined_point = self.refine_point_subpixel(image, x, y, size)

            # è®¡ç®—åœ†åº¦ï¼šä½¿ç”¨è½®å»“åˆ†æ
            circularity = self.calculate_blob_circularity(image, refined_point[0], refined_point[1], size)

            # è®¡ç®—åƒç´ é¢ç§¯ï¼šä½¿ç”¨è½®å»“åˆ†æ
            pixel_area = self.calculate_blob_pixel_area(image, refined_point[0], refined_point[1], size)

            points_with_features.append({
                'point': refined_point,
                'size': size,
                'circularity': circularity,
                'pixel_area': pixel_area,
                'response': kp.response  # blobæ£€æµ‹å™¨çš„å“åº”å¼ºåº¦
            })

        return points_with_features

    def refine_point_subpixel(self, image, x, y, size):
        """
        ä½¿ç”¨äºšåƒç´ ç²¾åº¦ä¼˜åŒ–ç‚¹ä½ç½®

        Args:
            image: è¾“å…¥å›¾åƒ
            x, y: åˆå§‹ç‚¹åæ ‡
            size: blobå¤§å°

        Returns:
            list: ä¼˜åŒ–åçš„ç‚¹åæ ‡ [x, y]
        """
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾åƒ
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image.copy()

            # å®šä¹‰æœç´¢çª—å£å¤§å°
            win_size = max(5, int(size / 4))

            # ä½¿ç”¨cornerSubPixè¿›è¡Œäºšåƒç´ ç²¾åº¦ä¼˜åŒ–
            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.01)

            # åˆå§‹ç‚¹åæ ‡
            corners = np.array([[x, y]], dtype=np.float32)

            # äºšåƒç´ ç²¾åº¦ä¼˜åŒ–
            refined_corners = cv2.cornerSubPix(
                gray,
                corners,
                (win_size, win_size),
                (-1, -1),
                criteria
            )

            refined_x, refined_y = refined_corners[0]

            # æ£€æŸ¥ä¼˜åŒ–ç»“æœæ˜¯å¦åˆç†ï¼ˆä¸åº”è¯¥åç§»å¤ªè¿œï¼‰
            max_offset = size / 2
            if abs(refined_x - x) > max_offset or abs(refined_y - y) > max_offset:
                # å¦‚æœåç§»è¿‡å¤§ï¼Œä½¿ç”¨åŸå§‹åæ ‡
                return [x, y]

            return [float(refined_x), float(refined_y)]

        except Exception:
            # å¦‚æœä¼˜åŒ–å¤±è´¥ï¼Œè¿”å›åŸå§‹åæ ‡
            return [x, y]

    def calculate_blob_circularity(self, image, x, y, size):
        """è®¡ç®—blobçš„åœ†åº¦"""
        try:
            # åˆ›å»ºä¸€ä¸ªå›´ç»•blobçš„å°åŒºåŸŸ
            radius = int(size / 2) + 5
            x_int, y_int = int(x), int(y)

            # ç¡®ä¿åŒºåŸŸåœ¨å›¾åƒèŒƒå›´å†… 

            x1 = max(0, x_int - radius)
            y1 = max(0, y_int - radius)
            x2 = min(image.shape[1], x_int + radius)
            y2 = min(image.shape[0], y_int + radius)

            if x2 <= x1 or y2 <= y1:
                return 0.0

            # æå–ROI
            roi = image[y1:y2, x1:x2]

            # äºŒå€¼åŒ–
            if self.detection_params['blob_color'] == 0:  # æš—è‰²blob
                _, binary = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            else:  # äº®è‰²blob
                _, binary = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            if not contours:
                return 0.0

            # æ‰¾åˆ°æœ€å¤§çš„è½®å»“ï¼ˆåº”è¯¥æ˜¯æˆ‘ä»¬çš„blobï¼‰
            largest_contour = max(contours, key=cv2.contourArea)
            area = cv2.contourArea(largest_contour)

            if area < 10:  # é¢ç§¯å¤ªå°
                return 0.0

            # è®¡ç®—å‘¨é•¿
            perimeter = cv2.arcLength(largest_contour, True)

            if perimeter == 0:
                return 0.0

            # è®¡ç®—åœ†åº¦ï¼š4Ï€*é¢ç§¯/å‘¨é•¿Â²
            circularity = 4 * np.pi * area / (perimeter * perimeter)

            # åœ†åº¦å€¼åº”è¯¥åœ¨0-1ä¹‹é—´ï¼Œå®Œç¾çš„åœ†ä¸º1
            return min(1.0, circularity)

        except Exception:
            # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
            return 0.5

    def calculate_blob_pixel_area(self, image, x, y, size):
        """è®¡ç®—blobçš„åƒç´ é¢ç§¯"""
        try:
            # åˆ›å»ºä¸€ä¸ªå›´ç»•blobçš„å°åŒºåŸŸ
            radius = int(size / 2) + 5
            x_int, y_int = int(x), int(y)

            # ç¡®ä¿åŒºåŸŸåœ¨å›¾åƒèŒƒå›´å†…
            x1 = max(0, x_int - radius)
            y1 = max(0, y_int - radius)
            x2 = min(image.shape[1], x_int + radius)
            y2 = min(image.shape[0], y_int + radius)

            if x2 <= x1 or y2 <= y1:
                return 0

            # æå–ROI
            roi = image[y1:y2, x1:x2]

            # äºŒå€¼åŒ–
            if self.detection_params['blob_color'] == 0:  # æš—è‰²blob
                _, binary = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            else:  # äº®è‰²blob
                _, binary = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            if not contours:
                return 0

            # æ‰¾åˆ°æœ€å¤§çš„è½®å»“ï¼ˆåº”è¯¥æ˜¯æˆ‘ä»¬çš„blobï¼‰
            largest_contour = max(contours, key=cv2.contourArea)
            area = cv2.contourArea(largest_contour)

            return int(area)

        except Exception:
            # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
            return 0

    def calculate_area_similarity_score(self, areas):
        """
        è®¡ç®—é¢ç§¯ç›¸ä¼¼æ€§å¾—åˆ†

        Args:
            areas: é¢ç§¯åˆ—è¡¨

        Returns:
            float: ç›¸ä¼¼æ€§å¾—åˆ†ï¼Œå€¼è¶Šé«˜è¡¨ç¤ºé¢ç§¯è¶Šç›¸ä¼¼
        """
        if len(areas) < 2:
            return 1.0

        areas = np.array(areas)
        mean_area = np.mean(areas)

        if mean_area == 0:
            return 0.0

        # è®¡ç®—å˜å¼‚ç³»æ•°ï¼ˆæ ‡å‡†å·®/å‡å€¼ï¼‰ï¼Œå€¼è¶Šå°è¡¨ç¤ºè¶Šç›¸ä¼¼
        cv = np.std(areas) / mean_area

        # è½¬æ¢ä¸ºç›¸ä¼¼æ€§å¾—åˆ†ï¼ˆ0-1ä¹‹é—´ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸ä¼¼ï¼‰
        similarity_score = np.exp(-cv * 2)  # ä½¿ç”¨æŒ‡æ•°å‡½æ•°ï¼Œcv=0æ—¶å¾—åˆ†ä¸º1

        return similarity_score

    def detect_area_outliers(self, markers_with_features):
        """
        æ£€æµ‹é¢ç§¯å¼‚å¸¸å€¼

        Args:
            markers_with_features: å¸¦ç‰¹å¾çš„æ ‡è®°ç‚¹åˆ—è¡¨

        Returns:
            tuple: (æ­£å¸¸ç‚¹åˆ—è¡¨, å¼‚å¸¸ç‚¹åˆ—è¡¨)
        """
        if len(markers_with_features) < 3:
            return markers_with_features, []

        areas = np.array([m['pixel_area'] for m in markers_with_features])

        # ä½¿ç”¨å››åˆ†ä½æ•°æ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
        Q1 = np.percentile(areas, 25)
        Q3 = np.percentile(areas, 75)
        IQR = Q3 - Q1

        # å¼‚å¸¸å€¼å®šä¹‰ï¼šè¶…å‡º Q1-1.5*IQR æˆ– Q3+1.5*IQR
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        normal_markers = []
        outlier_markers = []

        for marker in markers_with_features:
            area = marker['pixel_area']
            if lower_bound <= area <= upper_bound:
                normal_markers.append(marker)
            else:
                outlier_markers.append(marker)

        if outlier_markers:
            self.update_result_text(f"é¢ç§¯å¼‚å¸¸å€¼æ£€æµ‹:\n")
            self.update_result_text(f"  æ­£å¸¸èŒƒå›´: {lower_bound:.0f} - {upper_bound:.0f} åƒç´ \n")
            self.update_result_text(f"  æ­£å¸¸ç‚¹: {len(normal_markers)}ä¸ª\n")
            self.update_result_text(f"  å¼‚å¸¸ç‚¹: {len(outlier_markers)}ä¸ª\n")
            for marker in outlier_markers:
                self.update_result_text(f"    å¼‚å¸¸ç‚¹: ä½ç½®=({marker['point'][0]:.1f}, {marker['point'][1]:.1f}), "
                                      f"é¢ç§¯={marker['pixel_area']}åƒç´  (è¶…å‡ºæ­£å¸¸èŒƒå›´)\n")

        return normal_markers, outlier_markers

    def select_best_points_by_triple_criteria(self, markers_with_features, target_count=5):
        """
        åŸºäºä¸‰é‡æ ‡å‡†é€‰æ‹©æœ€ä½³ABCDEç‚¹ï¼š
        1. é¢ç§¯ç­›é€‰ï¼šç›´æ¥æ’é™¤é¢ç§¯å¼‚å¸¸çš„ç‚¹
        2. åœ†åº¦è¯„ä¼°ï¼šè¯„ä¼°ç‚¹çš„åœ†å½¢ç¨‹åº¦
        3. è“å›¾åŒ¹é…ï¼šè¯„ä¼°ä¸å™¨æ¢°åæ ‡è“å›¾çš„å‡ ä½•ç›¸ä¼¼æ€§

        Args:
            markers_with_features: å¸¦ç‰¹å¾çš„æ ‡è®°ç‚¹åˆ—è¡¨
            target_count: ç›®æ ‡ç‚¹æ•°é‡

        Returns:
            list: é€‰æ‹©çš„æœ€ä½³ç‚¹åˆ—è¡¨
        """
        if len(markers_with_features) <= target_count:
            return markers_with_features

        self.update_result_text(f"å¼€å§‹ä¸‰é‡æ ‡å‡†é€‰æ‹©æœ€ä½³{target_count}ä¸ªç‚¹...\n")
        self.update_result_text(f"æ ‡å‡†1: é¢ç§¯ç­›é€‰ â†’ æ ‡å‡†2: åœ†åº¦è¯„ä¼° â†’ æ ‡å‡†3: è“å›¾åŒ¹é…\n")

        # ç¬¬ä¸€æ­¥ï¼šé¢ç§¯ç­›é€‰ - ç›´æ¥æ’é™¤é¢ç§¯å¼‚å¸¸çš„ç‚¹
        self.update_result_text(f"\n=== ç¬¬ä¸€æ­¥ï¼šé¢ç§¯ç­›é€‰ ===\n")
        normal_markers, outlier_markers = self.detect_area_outliers(markers_with_features)

        if len(outlier_markers) > 0:
            self.update_result_text(f"æ’é™¤{len(outlier_markers)}ä¸ªé¢ç§¯å¼‚å¸¸ç‚¹:\n")
            for marker in outlier_markers:
                self.update_result_text(f"  âŒ ä½ç½®=({marker['point'][0]:.1f}, {marker['point'][1]:.1f}), "
                                      f"é¢ç§¯={marker['pixel_area']}åƒç´  (å¼‚å¸¸)\n")

        if len(normal_markers) < target_count:
            self.update_result_text(f"âš ï¸ é¢ç§¯æ­£å¸¸çš„ç‚¹ä¸å¤Ÿ({len(normal_markers)}ä¸ª)ï¼Œéœ€è¦åŒ…å«éƒ¨åˆ†é¢ç§¯å¼‚å¸¸ç‚¹\n")

            # æŒ‰é¢ç§¯å¼‚å¸¸ç¨‹åº¦æ’åºï¼Œé€‰æ‹©å¼‚å¸¸ç¨‹åº¦æœ€å°çš„ç‚¹
            if normal_markers:
                normal_areas = [m['pixel_area'] for m in normal_markers]
                median_area = np.median(normal_areas)
            else:
                all_areas = [m['pixel_area'] for m in markers_with_features]
                median_area = np.median(all_areas)

            # è®¡ç®—æ¯ä¸ªå¼‚å¸¸ç‚¹ä¸ä¸­ä½æ•°çš„å·®å¼‚ï¼Œé€‰æ‹©å·®å¼‚è¾ƒå°çš„
            outlier_markers_sorted = sorted(outlier_markers,
                                          key=lambda x: abs(x['pixel_area'] - median_area))

            needed_outliers = target_count - len(normal_markers)
            candidate_markers = normal_markers + outlier_markers_sorted[:needed_outliers]

            self.update_result_text(f"æ·»åŠ {needed_outliers}ä¸ªå¼‚å¸¸ç¨‹åº¦æœ€å°çš„å¼‚å¸¸ç‚¹:\n")
            for marker in outlier_markers_sorted[:needed_outliers]:
                self.update_result_text(f"  âœ… ä½ç½®=({marker['point'][0]:.1f}, {marker['point'][1]:.1f}), "
                                      f"é¢ç§¯={marker['pixel_area']}åƒç´  (å¼‚å¸¸ç¨‹åº¦è¾ƒå°)\n")
        else:
            candidate_markers = normal_markers
            self.update_result_text(f"âœ… ä½¿ç”¨{len(normal_markers)}ä¸ªé¢ç§¯æ­£å¸¸çš„ç‚¹è¿›è¡Œåç»­ç­›é€‰\n")

        # ç¬¬äºŒæ­¥ï¼šä»å€™é€‰ç‚¹ä¸­ï¼ŒåŸºäºåœ†åº¦å’Œè“å›¾åŒ¹é…ç»¼åˆé€‰æ‹©
        return self.select_by_circularity_and_blueprint_matching(candidate_markers, target_count)

    def select_by_circularity_and_blueprint_matching(self, candidate_markers, target_count=5):
        """
        åŸºäºåœ†åº¦å’Œè“å›¾åŒ¹é…ç»¼åˆé€‰æ‹©æœ€ä½³ç‚¹

        Args:
            candidate_markers: å€™é€‰æ ‡è®°ç‚¹åˆ—è¡¨ï¼ˆå·²é€šè¿‡é¢ç§¯ç­›é€‰ï¼‰
            target_count: ç›®æ ‡ç‚¹æ•°é‡

        Returns:
            list: é€‰æ‹©çš„æœ€ä½³ç‚¹åˆ—è¡¨
        """
        self.update_result_text(f"\n=== ç¬¬äºŒæ­¥ï¼šåœ†åº¦å’Œè“å›¾åŒ¹é…ç»¼åˆè¯„ä¼° ===\n")

        if len(candidate_markers) <= target_count:
            return candidate_markers

        # ä»å€™é€‰ç‚¹ä¸­é€‰æ‹©æ‰€æœ‰å¯èƒ½çš„5ç‚¹ç»„åˆï¼Œè¿›è¡Œç»¼åˆè¯„ä¼°
        from itertools import combinations

        # é™åˆ¶ç»„åˆæ•°é‡ï¼Œé¿å…è®¡ç®—è¿‡æ…¢
        if len(candidate_markers) > 12:
            # æŒ‰åœ†åº¦æ’åºï¼Œé€‰æ‹©å‰12ä¸ªè¿›è¡Œç»„åˆåˆ†æ
            candidate_markers = sorted(candidate_markers, key=lambda x: x['circularity'], reverse=True)[:12]
            self.update_result_text(f"å€™é€‰ç‚¹è¿‡å¤šï¼ŒæŒ‰åœ†åº¦æ’åºåé€‰æ‹©å‰12ä¸ªè¿›è¡Œç»„åˆåˆ†æ\n")

        self.update_result_text(f"å¼€å§‹åˆ†æ{len(candidate_markers)}ä¸ªå€™é€‰ç‚¹çš„{target_count}ç‚¹ç»„åˆ...\n")

        best_score = -1
        best_combination = None
        combination_count = 0

        # éå†æ‰€æœ‰å¯èƒ½çš„5ç‚¹ç»„åˆ
        for combination in combinations(candidate_markers, target_count):
            combination_count += 1

            # æå–ç‚¹åæ ‡
            points = [marker['point'] for marker in combination]

            # è®¡ç®—ä¸‰ä¸ªè¯„ä¼°æŒ‡æ ‡
            circularity_score = self.calculate_circularity_score(combination)
            blueprint_score = self.calculate_blueprint_matching_score(points)

            # ç»¼åˆè¯„åˆ†ï¼šåœ†åº¦æƒé‡0.5ï¼Œè“å›¾åŒ¹é…æƒé‡0.5
            combined_score = 0.6 * circularity_score + 0.4 * blueprint_score

            if combined_score > best_score:
                best_score = combined_score
                best_combination = combination

        self.update_result_text(f"åˆ†æäº†{combination_count}ç§ç»„åˆï¼Œæœ€ä½³ç»„åˆå¾—åˆ†: {best_score:.3f}\n")

        if best_combination:
            # æ˜¾ç¤ºæœ€ä½³ç»„åˆçš„è¯¦ç»†ä¿¡æ¯
            points = [marker['point'] for marker in best_combination]
            circularity_score = self.calculate_circularity_score(best_combination)
            blueprint_score = self.calculate_blueprint_matching_score(points)

            self.update_result_text(f"æœ€ä½³ç»„åˆè¯¦æƒ…:\n")
            self.update_result_text(f"  åœ†åº¦è¯„åˆ†: {circularity_score:.3f}\n")
            self.update_result_text(f"  è“å›¾åŒ¹é…è¯„åˆ†: {blueprint_score:.3f}\n")
            self.update_result_text(f"  ç»¼åˆå¾—åˆ†: {best_score:.3f}\n")

            return list(best_combination)
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„ç»„åˆï¼Œå›é€€åˆ°æŒ‰åœ†åº¦é€‰æ‹©
            self.update_result_text(f"æœªæ‰¾åˆ°åˆé€‚ç»„åˆï¼Œå›é€€åˆ°æŒ‰åœ†åº¦é€‰æ‹©\n")
            sorted_markers = sorted(candidate_markers, key=lambda x: x['circularity'], reverse=True)
            return sorted_markers[:target_count]

    def calculate_circularity_score(self, markers):
        """
        è®¡ç®—ä¸€ç»„ç‚¹çš„åœ†åº¦è¯„åˆ†

        Args:
            markers: æ ‡è®°ç‚¹åˆ—è¡¨

        Returns:
            float: åœ†åº¦è¯„åˆ† (0-1)
        """
        circularities = [marker['circularity'] for marker in markers]

        # å¹³å‡åœ†åº¦ä½œä¸ºåŸºç¡€åˆ†æ•°
        avg_circularity = np.mean(circularities)

        # åœ†åº¦ä¸€è‡´æ€§å¥–åŠ±ï¼šåœ†åº¦è¶Šä¸€è‡´ï¼Œå¥–åŠ±è¶Šé«˜
        circularity_std = np.std(circularities)
        consistency_bonus = np.exp(-circularity_std * 3)  # æ ‡å‡†å·®è¶Šå°ï¼Œå¥–åŠ±è¶Šé«˜

        # ç»¼åˆåœ†åº¦è¯„åˆ†
        circularity_score = 0.7 * avg_circularity + 0.3 * consistency_bonus

        return min(1.0, circularity_score)

    def calculate_blueprint_matching_score(self, points):
        """
        è®¡ç®—ç‚¹é›†ä¸å™¨æ¢°åæ ‡è“å›¾çš„å‡ ä½•ç›¸ä¼¼æ€§
        åŸºäºçº¿æ®µæ¯”ä¾‹ç›¸ä¼¼æ€§ï¼šæ£€æŸ¥å€™é€‰ç‚¹ç»„æˆçš„å›¾å½¢å„çº¿æ®µä¸è“å›¾æ¨¡å‹çš„çº¿æ®µæ˜¯å¦æˆæ¯”ä¾‹

        Args:
            points: ç‚¹åæ ‡åˆ—è¡¨ [[x1,y1], [x2,y2], ...]

        Returns:
            float: è“å›¾åŒ¹é…è¯„åˆ† (0-1)
        """
        if len(points) != 5:
            return 0.0

        # å™¨æ¢°åæ ‡è“å›¾ï¼ˆæ¥è‡ªå·¥å…·æ ‡å®šçš„çœŸå®ABCDEåæ ‡ï¼‰
        # ä½¿ç”¨tool_tip_calibration.pyä¸­å®šä¹‰çš„å®é™…å·¥å…·åæ ‡
        ideal_blueprint = np.array([
            [0.0, 0.0],           # Aç‚¹ä¸ºåŸç‚¹
            [87.5, 0.0],          # Bç‚¹åœ¨Xè½´ä¸Š
            [33.6, 21.1],         # Cç‚¹åæ ‡
            [25.3, -33.6],        # Dç‚¹åæ ‡
            [48.9, -57.5]         # Eç‚¹åæ ‡
        ], dtype=np.float32)

        try:
            # è®¡ç®—æ£€æµ‹ç‚¹é›†çš„æ‰€æœ‰çº¿æ®µé•¿åº¦
            detected_distances = self.calculate_all_distances(points)

            # è®¡ç®—ç†æƒ³è“å›¾çš„æ‰€æœ‰çº¿æ®µé•¿åº¦
            ideal_distances = self.calculate_all_distances(ideal_blueprint.tolist())

            # è®¡ç®—çº¿æ®µæ¯”ä¾‹ç›¸ä¼¼æ€§
            similarity_score = self.calculate_distance_ratio_similarity(detected_distances, ideal_distances)

            self.update_result_text(f"    è“å›¾åŒ¹é…åˆ†æ: çº¿æ®µæ¯”ä¾‹ç›¸ä¼¼æ€§å¾—åˆ†={similarity_score:.3f}\n")

            return similarity_score

        except Exception as e:
            self.update_result_text(f"    è“å›¾åŒ¹é…è®¡ç®—å¤±è´¥: {e}\n")
            return 0.0

    def calculate_all_distances(self, points):
        """
        è®¡ç®—ç‚¹é›†ä¸­æ‰€æœ‰ç‚¹å¯¹ä¹‹é—´çš„è·ç¦»

        Args:
            points: ç‚¹åæ ‡åˆ—è¡¨ [[x1,y1], [x2,y2], ...]

        Returns:
            list: æ‰€æœ‰ç‚¹å¯¹è·ç¦»çš„åˆ—è¡¨
        """
        distances = []
        points_array = np.array(points, dtype=np.float32)

        for i in range(len(points_array)):
            for j in range(i+1, len(points_array)):
                dist = np.linalg.norm(points_array[i] - points_array[j])
                distances.append(dist)

        return distances

    def calculate_distance_ratio_similarity(self, detected_distances, ideal_distances):
        """
        è®¡ç®—ä¸¤ç»„è·ç¦»çš„æ¯”ä¾‹ç›¸ä¼¼æ€§

        Args:
            detected_distances: æ£€æµ‹ç‚¹çš„è·ç¦»åˆ—è¡¨
            ideal_distances: ç†æƒ³è“å›¾çš„è·ç¦»åˆ—è¡¨

        Returns:
            float: ç›¸ä¼¼æ€§å¾—åˆ† (0-1)
        """
        if len(detected_distances) != len(ideal_distances):
            return 0.0

        # å°†è·ç¦»åˆ—è¡¨æ’åºï¼Œä»¥ä¾¿æ¯”è¾ƒå¯¹åº”çš„çº¿æ®µ
        detected_sorted = sorted(detected_distances)
        ideal_sorted = sorted(ideal_distances)

        # è®¡ç®—æ¯”ä¾‹å› å­ï¼ˆä½¿ç”¨æœ€é•¿çš„çº¿æ®µä½œä¸ºåŸºå‡†ï¼‰
        if ideal_sorted[-1] == 0:
            return 0.0

        scale_factor = detected_sorted[-1] / ideal_sorted[-1]

        # å°†ç†æƒ³è·ç¦»æŒ‰æ¯”ä¾‹ç¼©æ”¾
        scaled_ideal = [d * scale_factor for d in ideal_sorted]

        # è®¡ç®—ç›¸å¯¹è¯¯å·®
        relative_errors = []
        for detected, scaled in zip(detected_sorted, scaled_ideal):
            if scaled > 0:
                relative_error = abs(detected - scaled) / scaled
                relative_errors.append(relative_error)

        if not relative_errors:
            return 0.0

        # è®¡ç®—å¹³å‡ç›¸å¯¹è¯¯å·®
        avg_relative_error = np.mean(relative_errors)

        # è½¬æ¢ä¸ºç›¸ä¼¼æ€§å¾—åˆ†ï¼šè¯¯å·®è¶Šå°ï¼Œå¾—åˆ†è¶Šé«˜
        # ä½¿ç”¨æŒ‡æ•°å‡½æ•°ï¼Œå½“å¹³å‡ç›¸å¯¹è¯¯å·®ä¸º0æ—¶å¾—åˆ†ä¸º1ï¼Œè¯¯å·®å¢å¤§æ—¶å¾—åˆ†å¿«é€Ÿä¸‹é™
        similarity_score = np.exp(-avg_relative_error * 5)  # 5æ˜¯è°ƒèŠ‚å‚æ•°ï¼Œæ§åˆ¶å¾—åˆ†ä¸‹é™é€Ÿåº¦

        return similarity_score

    def undistort_points(self, points):
        """
        ä½¿ç”¨ç›¸æœºæ ‡å®šå‚æ•°å¯¹ç‚¹è¿›è¡Œå»ç•¸å˜å¤„ç†

        æ³¨æ„ï¼šæ­¤æ–¹æ³•ä»…ç”¨äºæ˜¾ç¤ºå¯¹æ¯”ï¼Œå®é™…çš„PnPæ±‚è§£ä¸­ï¼Œ
        solvePnPä¼šå†…éƒ¨è‡ªåŠ¨å¤„ç†ç•¸å˜ï¼Œé¿å…é‡å¤å»ç•¸å˜ã€‚

        Args:
            points: åŸå§‹ç‚¹åæ ‡åˆ—è¡¨ [[x1,y1], [x2,y2], ...]

        Returns:
            list: å»ç•¸å˜åçš„ç‚¹åæ ‡åˆ—è¡¨ [[x1,y1], [x2,y2], ...]
        """
        if not points:
            return points

        # è½¬æ¢ä¸ºnumpyæ•°ç»„æ ¼å¼ï¼ŒOpenCVè¦æ±‚çš„æ ¼å¼
        points_array = np.array(points, dtype=np.float32).reshape(-1, 1, 2)

        # ä½¿ç”¨cv2.undistortPointsè¿›è¡Œå»ç•¸å˜
        # æ³¨æ„ï¼šcv2.undistortPointsè¿”å›çš„æ˜¯å½’ä¸€åŒ–åæ ‡ï¼Œéœ€è¦è½¬æ¢å›åƒç´ åæ ‡
        undistorted_normalized = cv2.undistortPoints(
            points_array,
            self.camera_matrix,
            self.dist_coeffs,
            P=self.camera_matrix  # ä½¿ç”¨På‚æ•°ç›´æ¥å¾—åˆ°åƒç´ åæ ‡
        )

        # è½¬æ¢å›åˆ—è¡¨æ ¼å¼
        undistorted_points = undistorted_normalized.reshape(-1, 2).tolist()

        # æ˜¾ç¤ºå»ç•¸å˜å‰åçš„å¯¹æ¯”ï¼ˆä»…ç”¨äºæ˜¾ç¤ºï¼Œå®é™…PnPæ±‚è§£ç”±solvePnPå†…éƒ¨å¤„ç†ç•¸å˜ï¼‰
        self.update_result_text("å»ç•¸å˜æ•ˆæœå¯¹æ¯”ï¼ˆä»…ä¾›å‚è€ƒï¼Œå®é™…ç”±solvePnPå†…éƒ¨å¤„ç†ï¼‰:\n")
        for i, (orig, undist) in enumerate(zip(points, undistorted_points)):
            diff_x = undist[0] - orig[0]
            diff_y = undist[1] - orig[1]
            diff_magnitude = np.sqrt(diff_x**2 + diff_y**2)
            self.update_result_text(f"  ç‚¹{i+1}: ({orig[0]:.1f},{orig[1]:.1f}) â†’ ({undist[0]:.1f},{undist[1]:.1f}) åç§»:{diff_magnitude:.2f}åƒç´ \n")

        return undistorted_points

    def select_best_5_points(self, markers):
        """
        åŸºäºè“å›¾åæ ‡ç›¸ä¼¼æ€§åŒ¹é…ABCDEç‚¹

        ç­–ç•¥ï¼š
        1. ä½¿ç”¨å·²çŸ¥çš„ABCDEè“å›¾åæ ‡ä½œä¸ºå‚è€ƒæ¨¡æ¿
        2. è®¡ç®—æ£€æµ‹ç‚¹ä¸è“å›¾çš„å½¢çŠ¶ç›¸ä¼¼æ€§
        3. æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„æ’åˆ—ç»„åˆ
        4. åŸºäºå‡ ä½•å½¢çŠ¶åŒ¹é…ï¼Œä¸ä¾èµ–æœ€é•¿è¾¹

        Args:
            markers: æ£€æµ‹åˆ°çš„æ ‡è®°ç‚¹åˆ—è¡¨ [[x1,y1], [x2,y2], ...]

        Returns:
            dict: é€‰æ‹©çš„ABCDEç‚¹ {'A': (x,y), 'B': (x,y), 'C': (x,y), 'D': (x,y), 'E': (x,y)}
        """
        if len(markers) != 5:
            raise ValueError(f"éœ€è¦æ°å¥½5ä¸ªæ ‡è®°ç‚¹ï¼Œä½†æ£€æµ‹åˆ°{len(markers)}ä¸ª")

        markers = np.array(markers)
        self.update_result_text(f"å¼€å§‹åŸºäºè“å›¾ç›¸ä¼¼æ€§åŒ¹é…ABCDEç‚¹...\n")
        for i, marker in enumerate(markers):
            self.update_result_text(f"  æ£€æµ‹ç‚¹{i+1}: ({marker[0]:.1f}, {marker[1]:.1f})\n")

        # ABCDEè“å›¾åæ ‡ï¼ˆå™¨æ¢°åæ ‡ç³»ï¼Œå•ä½ï¼šmmï¼‰
        blueprint_3d = np.array([
            [0.0, 0.0, 0.0],      # Aç‚¹ï¼šåŸç‚¹
            [87.5, 0.0, 0.0],     # Bç‚¹ï¼šXè½´ä¸Š
            [33.6, 21.1, 0.0],    # Cç‚¹
            [25.3, -33.6, 0.0],   # Dç‚¹
            [48.9, -57.5, 0.0]    # Eç‚¹
        ], dtype=np.float32)

        # æå–2Dè“å›¾åæ ‡ï¼ˆå¿½ç•¥Zåæ ‡ï¼Œå› ä¸ºéƒ½æ˜¯0ï¼‰
        blueprint_2d = blueprint_3d[:, :2]

        self.update_result_text(f"è“å›¾åæ ‡å‚è€ƒ:\n")
        labels = ['A', 'B', 'C', 'D', 'E']
        for i, (label, point) in enumerate(zip(labels, blueprint_2d)):
            self.update_result_text(f"  {label}ç‚¹è“å›¾: ({point[0]:.1f}, {point[1]:.1f})\n")

        # å°è¯•æ‰€æœ‰å¯èƒ½çš„æ’åˆ—ç»„åˆï¼Œæ‰¾åˆ°æœ€ä½³åŒ¹é…
        from itertools import permutations

        best_score = float('inf')
        best_assignment = None
        best_transform = None

        self.update_result_text(f"å¼€å§‹å°è¯•æ‰€æœ‰æ’åˆ—ç»„åˆåŒ¹é…...\n")

        # éå†æ‰€æœ‰å¯èƒ½çš„ç‚¹åˆ†é…
        for perm in permutations(range(5)):
            # å½“å‰æ’åˆ—ï¼šmarkers[perm[i]] å¯¹åº” blueprint_2d[i]
            current_markers = markers[list(perm)]

            # è®¡ç®—ä»è“å›¾åˆ°æ£€æµ‹ç‚¹çš„ç›¸ä¼¼å˜æ¢
            transform_score, transform_params = self.calculate_similarity_transform(blueprint_2d, current_markers)

            if transform_score < best_score:
                best_score = transform_score
                best_assignment = perm
                best_transform = transform_params

        self.update_result_text(f"æœ€ä½³åŒ¹é…å¾—åˆ†: {best_score:.3f}\n")
        self.update_result_text(f"å˜æ¢å‚æ•°: ç¼©æ”¾={best_transform['scale']:.3f}, æ—‹è½¬={best_transform['rotation']:.1f}Â°, å¹³ç§»=({best_transform['translation'][0]:.1f}, {best_transform['translation'][1]:.1f})\n")

        # æ ¹æ®æœ€ä½³åˆ†é…åˆ›å»ºç»“æœ
        result_points = {}
        for i, label in enumerate(labels):
            marker_idx = best_assignment[i]
            point = markers[marker_idx]
            result_points[label] = (float(point[0]), float(point[1]))
            self.update_result_text(f"{label}ç‚¹åŒ¹é…: æ£€æµ‹ç‚¹{marker_idx+1} ({point[0]:.1f}, {point[1]:.1f})\n")

        return result_points

    def calculate_similarity_transform(self, template_points, detected_points):
        """
        è®¡ç®—ä»æ¨¡æ¿ç‚¹åˆ°æ£€æµ‹ç‚¹çš„ç›¸ä¼¼å˜æ¢ï¼Œå¹¶è¿”å›åŒ¹é…å¾—åˆ†

        ç›¸ä¼¼å˜æ¢åŒ…æ‹¬ï¼šç¼©æ”¾ã€æ—‹è½¬ã€å¹³ç§»

        Args:
            template_points: æ¨¡æ¿ç‚¹åæ ‡ (5x2)
            detected_points: æ£€æµ‹ç‚¹åæ ‡ (5x2)

        Returns:
            tuple: (åŒ¹é…å¾—åˆ†, å˜æ¢å‚æ•°å­—å…¸)
        """
        try:
            # è®¡ç®—è´¨å¿ƒ
            template_center = np.mean(template_points, axis=0)
            detected_center = np.mean(detected_points, axis=0)

            # ä¸­å¿ƒåŒ–
            template_centered = template_points - template_center
            detected_centered = detected_points - detected_center

            # è®¡ç®—ç¼©æ”¾å› å­ï¼ˆä½¿ç”¨RMSè·ç¦»æ¯”ï¼‰
            template_rms = np.sqrt(np.mean(np.sum(template_centered**2, axis=1)))
            detected_rms = np.sqrt(np.mean(np.sum(detected_centered**2, axis=1)))

            if template_rms == 0 or detected_rms == 0:
                return float('inf'), {}

            scale = detected_rms / template_rms

            # ç¼©æ”¾æ¨¡æ¿ç‚¹
            template_scaled = template_centered * scale

            # è®¡ç®—æ—‹è½¬è§’åº¦ï¼ˆä½¿ç”¨Procrustesåˆ†æï¼‰
            # H = template_scaled.T @ detected_centered
            H = np.dot(template_scaled.T, detected_centered)
            U, _, Vt = np.linalg.svd(H)
            R = np.dot(Vt.T, U.T)

            # ç¡®ä¿æ˜¯æ—‹è½¬çŸ©é˜µï¼ˆè¡Œåˆ—å¼ä¸º1ï¼‰
            if np.linalg.det(R) < 0:
                Vt[-1, :] *= -1
                R = np.dot(Vt.T, U.T)

            # è®¡ç®—æ—‹è½¬è§’åº¦
            rotation_angle = np.arctan2(R[1, 0], R[0, 0]) * 180 / np.pi

            # åº”ç”¨å˜æ¢åˆ°æ¨¡æ¿ç‚¹
            template_transformed = np.dot(template_scaled, R.T) + detected_center

            # è®¡ç®—åŒ¹é…è¯¯å·®ï¼ˆRMSè·ç¦»ï¼‰
            distances = np.sqrt(np.sum((template_transformed - detected_points)**2, axis=1))
            rms_error = np.sqrt(np.mean(distances**2))

            transform_params = {
                'scale': scale,
                'rotation': rotation_angle,
                'translation': detected_center - template_center * scale,
                'rms_error': rms_error
            }

            return rms_error, transform_params

        except Exception:
            return float('inf'), {}

    def detect_points(self):
        """åˆ†åˆ«æ£€æµ‹ä¸¤å¼ å›¾ç‰‡çš„æ ‡è®°ç‚¹"""
        if not self.start_image or not self.end_image:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆæ‹æ‘„ä¸¤å¼ å›¾ç‰‡ï¼ˆèµ·å§‹ç‚¹å’Œç»ˆç‚¹ï¼‰")
            return

        try:
            self.status_var.set("æ­£åœ¨æ£€æµ‹ä¸¤å¼ å›¾ç‰‡çš„æ ‡è®°ç‚¹...")
            self.update_result_text("ğŸ” å¼€å§‹åˆ†åˆ«æ£€æµ‹èµ·å§‹ç‚¹å’Œç»ˆç‚¹å›¾ç‰‡çš„æ ‡è®°ç‚¹...\n")

            # æ£€æµ‹èµ·å§‹ç‚¹å›¾ç‰‡
            self.update_result_text("\nğŸ“ æ£€æµ‹èµ·å§‹ç‚¹å›¾ç‰‡æ ‡è®°ç‚¹:\n")
            self.start_points = self.detect_single_image_points(self.start_image, "èµ·å§‹ç‚¹")

            # æ£€æµ‹ç»ˆç‚¹å›¾ç‰‡
            self.update_result_text("\nğŸ¯ æ£€æµ‹ç»ˆç‚¹å›¾ç‰‡æ ‡è®°ç‚¹:\n")
            self.end_points = self.detect_single_image_points(self.end_image, "ç»ˆç‚¹")

            if self.start_points is not None and self.end_points is not None:
                self.calculate_tip_btn.config(state=tk.NORMAL)
                self.update_result_text("\nâœ… ä¸¤å¼ å›¾ç‰‡çš„æ ‡è®°ç‚¹æ£€æµ‹å®Œæˆï¼\n")
                self.status_var.set("âœ… æ ‡è®°ç‚¹æ£€æµ‹å®Œæˆï¼Œå¯ä»¥è®¡ç®—è·ç¦»")

                # æ˜¾ç¤ºå¸¦æœ‰æ ‡è®°ç‚¹çš„å¹¶æ’å›¾åƒ
                self.display_dual_images_with_points()
            else:
                raise Exception("æ ‡è®°ç‚¹æ£€æµ‹å¤±è´¥")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"æ£€æµ‹æ ‡è®°ç‚¹å¤±è´¥: {e}")
            self.status_var.set("æ£€æµ‹å¤±è´¥")
            self.update_result_text(f"âŒ æ£€æµ‹å¤±è´¥: {e}\n")

    def detect_single_image_points(self, image_path, image_type):
        """æ£€æµ‹å•å¼ å›¾ç‰‡çš„æ ‡è®°ç‚¹"""
        try:
            # åŠ è½½å›¾ç‰‡
            image = cv2.imread(image_path)
            if image is None:
                raise Exception(f"æ— æ³•åŠ è½½{image_type}å›¾ç‰‡")

            self.update_result_text(f"æ­£åœ¨æ£€æµ‹{image_type}å›¾ç‰‡æ ‡è®°ç‚¹...\n")

            # å›¾åƒé¢„å¤„ç†
            processed_image = self.preprocess_image(image)
            self.update_result_text(f"{image_type}å›¾åƒé¢„å¤„ç†å®Œæˆ\n")

            # æ£€æµ‹blobï¼ˆè¿”å›å¸¦ç‰¹å¾çš„ç‚¹ï¼‰
            markers_with_features = self.detect_blobs(processed_image)
            self.update_result_text(f"{image_type}åˆæ­¥æ£€æµ‹åˆ° {len(markers_with_features)} ä¸ªå€™é€‰ç‚¹\n")

            # æ˜¾ç¤ºæ‰€æœ‰æ£€æµ‹åˆ°çš„ç‚¹çš„è¯¦ç»†ä¿¡æ¯
            if markers_with_features:
                self.update_result_text(f"\n{image_type}æ£€æµ‹åˆ°çš„ç‚¹çš„è¯¦ç»†ä¿¡æ¯:\n")
                self.update_result_text(f"{'åºå·':<4} {'ä½ç½®':<15} {'åœ†åº¦':<8} {'é¢ç§¯':<8} {'å“åº”å¼ºåº¦':<10}\n")
                self.update_result_text(f"{'-'*4} {'-'*15} {'-'*8} {'-'*8} {'-'*10}\n")

                # æŒ‰åœ†åº¦é™åºæ’åºæ˜¾ç¤º
                sorted_markers = sorted(markers_with_features, key=lambda x: x['circularity'], reverse=True)
                for i, marker in enumerate(sorted_markers):
                    pos_str = f"({marker['point'][0]:.1f},{marker['point'][1]:.1f})"
                    self.update_result_text(f"{i+1:<4} {pos_str:<15} {marker['circularity']:.3f}{'':4} {marker['pixel_area']:<8} {marker['response']:.3f}\n")

                # ç»Ÿè®¡ä¿¡æ¯
                areas = [m['pixel_area'] for m in markers_with_features]
                circularities = [m['circularity'] for m in markers_with_features]

                self.update_result_text(f"\n{image_type}ç»Ÿè®¡ä¿¡æ¯:\n")
                self.update_result_text(f"  åœ†åº¦èŒƒå›´: {min(circularities):.3f} - {max(circularities):.3f}\n")
                self.update_result_text(f"  åœ†åº¦å¹³å‡: {np.mean(circularities):.3f} Â± {np.std(circularities):.3f}\n")
                self.update_result_text(f"  é¢ç§¯èŒƒå›´: {min(areas)} - {max(areas)} åƒç´ \n")
                self.update_result_text(f"  é¢ç§¯å¹³å‡: {np.mean(areas):.1f} Â± {np.std(areas):.1f} åƒç´ \n")
                self.update_result_text(f"  é¢ç§¯å˜å¼‚ç³»æ•°: {np.std(areas)/np.mean(areas):.3f}\n")
            else:
                self.update_result_text(f"{image_type}æœªæ£€æµ‹åˆ°ä»»ä½•å€™é€‰ç‚¹\n")

            if len(markers_with_features) >= 5:
                # ä½¿ç”¨ä¸‰é‡æ ‡å‡†é€‰æ‹©æœ€ä½³çš„5ä¸ªç‚¹ï¼ˆé¢ç§¯ç­›é€‰ + åœ†åº¦è¯„ä¼° + è“å›¾åŒ¹é…ï¼‰
                selected_markers = self.select_best_points_by_triple_criteria(markers_with_features, 5)

                self.update_result_text(f"{image_type}æœ€ç»ˆé€‰æ‹©çš„5ä¸ªç‚¹:\n")
                for i, marker in enumerate(selected_markers):
                    self.update_result_text(f"  é€‰ä¸­ç‚¹{i+1}: åœ†åº¦={marker['circularity']:.3f}, "
                                          f"é¢ç§¯={marker['pixel_area']}åƒç´ , "
                                          f"ä½ç½®=({marker['point'][0]:.1f}, {marker['point'][1]:.1f})\n")

                # æå–ç‚¹åæ ‡ç”¨äºåç»­å¤„ç†
                markers = [marker['point'] for marker in selected_markers]

                # ç›´æ¥ä½¿ç”¨åŸå§‹ç‚¹è¿›è¡Œæ™ºèƒ½ABCDEæ’åºï¼ˆä¸è¿›è¡Œæ‰‹åŠ¨å»ç•¸å˜ï¼‰
                # solvePnPä¼šåœ¨å†…éƒ¨è‡ªåŠ¨å¤„ç†ç•¸å˜ï¼Œé¿å…é‡å¤å»ç•¸å˜
                abcde_points = self.select_best_5_points(markers)
                self.update_result_text(f"{image_type}ABCDEç‚¹æ’åºå®Œæˆ\n")

                # æŒ‰ABCDEé¡ºåºæ’åˆ—ç‚¹ï¼ˆåŸå§‹ç•¸å˜ç‚¹ï¼ŒsolvePnPä¼šå†…éƒ¨å»ç•¸å˜ï¼‰
                detected_points = np.array([
                    abcde_points['A'],
                    abcde_points['B'],
                    abcde_points['C'],
                    abcde_points['D'],
                    abcde_points['E']
                ], dtype=np.float32)

                self.update_result_text(f"âœ… {image_type}æˆåŠŸæ£€æµ‹å¹¶æ’åº5ä¸ªæ ‡è®°ç‚¹ (ABCDE)\n")
                labels = ['A', 'B', 'C', 'D', 'E']
                for point, label in zip(detected_points, labels):
                    self.update_result_text(f"  {label}ç‚¹: ({point[0]:.1f}, {point[1]:.1f})\n")

                # ä¿å­˜æ ‡æ³¨åçš„å›¾åƒåˆ°æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                result_image = self.draw_detected_points_on_image(
                    image, markers_with_features, selected_markers, detected_points, image_type
                )

                return detected_points
            else:
                raise Exception(f"{image_type}åªæ£€æµ‹åˆ° {len(markers_with_features)} ä¸ªç‚¹ï¼Œéœ€è¦è‡³å°‘5ä¸ªç‚¹")

        except Exception as e:
            self.update_result_text(f"âŒ {image_type}æ£€æµ‹å¤±è´¥: {e}\n")
            return None

    def draw_detected_points_on_image(self, image, markers_with_features, selected_markers, detected_points, image_type):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹åˆ°çš„æ ‡è®°ç‚¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        result_image = image.copy()

        # åœ¨å›¾åƒé¡¶éƒ¨æ˜¾ç¤ºå€™é€‰ç‚¹æ€»æ•°å’Œå›¾åƒç±»å‹
        header_text = f"{image_type.upper()} - Total Candidates: {len(markers_with_features)}"
        cv2.putText(result_image, header_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 3)  # ç™½è‰²èƒŒæ™¯
        cv2.putText(result_image, header_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)      # çº¢è‰²æ–‡å­—

        # ç»˜åˆ¶æ‰€æœ‰å€™é€‰ç‚¹ï¼ˆæµ…ç°è‰²ï¼Œè¾ƒå°ï¼‰å¹¶æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        for i, marker in enumerate(markers_with_features):
            point = marker['point']
            x, y = int(point[0]), int(point[1])

            # ç»˜åˆ¶å€™é€‰ç‚¹
            cv2.circle(result_image, (x, y), 6, (200, 200, 200), 2)
            cv2.circle(result_image, (x, y), 2, (150, 150, 150), -1)

            # æ˜¾ç¤ºç‚¹çš„åºå·ï¼ˆç™½è‰²èƒŒæ™¯ï¼Œé»‘è‰²æ–‡å­—ï¼‰
            cv2.putText(result_image, f"{i+1}", (x+10, y-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
            cv2.putText(result_image, f"{i+1}", (x+10, y-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)

            # æ˜¾ç¤ºåœ†åº¦å€¼ï¼ˆè“è‰²ï¼‰
            circularity_text = f"C:{marker['circularity']:.3f}"
            cv2.putText(result_image, circularity_text, (x+10, y+8),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 2)
            cv2.putText(result_image, circularity_text, (x+10, y+8),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)

            # æ˜¾ç¤ºé¢ç§¯å€¼ï¼ˆç»¿è‰²ï¼‰
            area_text = f"A:{marker['pixel_area']}"
            cv2.putText(result_image, area_text, (x+10, y+25),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 2)
            cv2.putText(result_image, area_text, (x+10, y+25),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)

        # ç»˜åˆ¶é€‰ä¸­çš„5ä¸ªå€™é€‰ç‚¹ï¼ˆçº¢è‰²ï¼Œæ›´å¤§ï¼‰
        for i, marker in enumerate(selected_markers):
            point = marker['point']
            x, y = int(point[0]), int(point[1])

            # ç»˜åˆ¶é€‰ä¸­æ ‡è®°ï¼ˆçº¢è‰²åœ†åœˆï¼‰
            cv2.circle(result_image, (x, y), 10, (0, 0, 255), 3)
            cv2.circle(result_image, (x, y), 3, (0, 0, 255), -1)

            # æ˜¾ç¤º"SELECTED"æ ‡è®°ï¼ˆçº¢è‰²ï¼‰
            cv2.putText(result_image, "SELECTED", (x-30, y-40),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
            cv2.putText(result_image, "SELECTED", (x-30, y-40),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)

        # ç»˜åˆ¶ABCDEç‚¹ï¼ˆä¸åŒé¢œè‰²ï¼Œæœ€çªå‡ºï¼‰
        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]  # è“ç»¿çº¢é»„ç´«
        labels = ['A', 'B', 'C', 'D', 'E']

        for point, color, label in zip(detected_points, colors, labels):
            x, y = int(point[0]), int(point[1])

            # ç»˜åˆ¶æœ€ç»ˆé€‰æ‹©çš„ç‚¹ï¼ˆå¤§åœ†åœˆï¼‰
            cv2.circle(result_image, (x, y), 15, color, -1)
            cv2.circle(result_image, (x, y), 18, (255, 255, 255), 3)  # ç™½è‰²è¾¹æ¡†

            # æ˜¾ç¤ºABCDEæ ‡ç­¾ï¼ˆå¤§å­—ä½“ï¼‰
            cv2.putText(result_image, label, (x+25, y+8),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
            cv2.putText(result_image, label, (x+25, y+8),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 2)

        # åœ¨å³ä¸Šè§’æ˜¾ç¤ºæ£€æµ‹å®ŒæˆçŠ¶æ€ï¼ˆä½¿ç”¨æ›´çŸ­çš„æ–‡å­—ï¼‰
        status_text = "DETECTED"
        text_width = 120  # ä¼°ç®—æ–‡å­—å®½åº¦
        cv2.putText(result_image, status_text,
                   (result_image.shape[1] - text_width, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 3)
        cv2.putText(result_image, status_text,
                   (result_image.shape[1] - text_width, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

        # ä¿å­˜æ ‡æ³¨åçš„å›¾åƒ
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        # ä½¿ç”¨è‹±æ–‡åç§°é¿å…ç¼–ç é—®é¢˜
        image_type_en = "start" if "èµ·å§‹" in image_type else "end"
        output_filename = f"images/detected_{image_type_en}_{timestamp}.jpg"
        cv2.imwrite(output_filename, result_image)
        self.update_result_text(f"  æ ‡æ³¨å›¾åƒå·²ä¿å­˜: {output_filename}\n")

        return result_image

    def display_dual_images_with_points(self):
        """æ˜¾ç¤ºå¸¦æœ‰æ ‡è®°ç‚¹çš„èµ·å§‹ç‚¹å’Œç»ˆç‚¹å›¾åƒå¹¶æ’"""
        if not self.start_image or not self.end_image:
            return

        try:
            # è¯»å–ä¸¤å¼ å›¾ç‰‡
            start_img = cv2.imread(self.start_image)
            end_img = cv2.imread(self.end_image)

            if start_img is None or end_img is None:
                self.update_result_text("âŒ æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶\n")
                return

            # åœ¨å›¾åƒä¸Šç»˜åˆ¶æ ‡è®°ç‚¹
            start_with_points = self.draw_points_on_single_image(start_img, self.start_points, "START")
            end_with_points = self.draw_points_on_single_image(end_img, self.end_points, "END")

            # è½¬æ¢é¢œè‰²ç©ºé—´
            start_rgb = cv2.cvtColor(start_with_points, cv2.COLOR_BGR2RGB)
            end_rgb = cv2.cvtColor(end_with_points, cv2.COLOR_BGR2RGB)

            # è°ƒæ•´å›¾ç‰‡å¤§å°ä½¿å…¶ä¸€è‡´
            target_height = 400
            start_h, start_w = start_rgb.shape[:2]
            end_h, end_w = end_rgb.shape[:2]

            # æŒ‰æ¯”ä¾‹ç¼©æ”¾
            start_scale = target_height / start_h
            end_scale = target_height / end_h

            start_new_w = int(start_w * start_scale)
            end_new_w = int(end_w * end_scale)

            start_resized = cv2.resize(start_rgb, (start_new_w, target_height))
            end_resized = cv2.resize(end_rgb, (end_new_w, target_height))

            # åˆ›å»ºå¹¶æ’å›¾åƒ
            gap = 30
            total_width = start_new_w + end_new_w + gap
            combined_img = np.ones((target_height, total_width, 3), dtype=np.uint8) * 240

            # æ”¾ç½®å›¾ç‰‡
            combined_img[:, :start_new_w] = start_resized
            combined_img[:, start_new_w+gap:start_new_w+gap+end_new_w] = end_resized

            # æ·»åŠ æ ‡ç­¾
            cv2.putText(combined_img, "START POINT", (10, 40),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)
            cv2.putText(combined_img, "END POINT", (start_new_w+gap+10, 40),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)

            # æ·»åŠ åˆ†éš”çº¿
            line_x = start_new_w + gap // 2
            cv2.line(combined_img, (line_x, 0), (line_x, target_height), (100, 100, 100), 2)

            # è½¬æ¢ä¸ºPILå›¾åƒå¹¶æ˜¾ç¤º
            pil_image = Image.fromarray(combined_img)
            photo = ImageTk.PhotoImage(pil_image)

            self.image_label.configure(image=photo)
            self.image_label.image = photo

            self.update_result_text("ğŸ“· å·²æ˜¾ç¤ºå¸¦æœ‰æ ‡è®°ç‚¹çš„èµ·å§‹ç‚¹å’Œç»ˆç‚¹å›¾åƒ\n")

        except Exception as e:
            self.update_result_text(f"âŒ æ˜¾ç¤ºå›¾ç‰‡å¤±è´¥: {e}\n")

    def draw_points_on_single_image(self, image, detected_points, image_type):
        """åœ¨å•å¼ å›¾åƒä¸Šç»˜åˆ¶ABCDEæ ‡è®°ç‚¹"""
        result_image = image.copy()

        if detected_points is None:
            return result_image

        # ç»˜åˆ¶ABCDEç‚¹ï¼ˆä¸åŒé¢œè‰²ï¼Œæ›´çªå‡ºï¼‰
        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255)]  # è“ç»¿çº¢é»„ç´«
        labels = ['A', 'B', 'C', 'D', 'E']

        for point, color, label in zip(detected_points, colors, labels):
            # ç»˜åˆ¶å¤§åœ†ç‚¹
            cv2.circle(result_image, (int(point[0]), int(point[1])), 15, color, -1)
            cv2.circle(result_image, (int(point[0]), int(point[1])), 18, (255, 255, 255), 3)  # ç™½è‰²è¾¹æ¡†

            # ç»˜åˆ¶æ ‡ç­¾
            cv2.putText(result_image, label, (int(point[0])+25, int(point[1])+8),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)
            cv2.putText(result_image, label, (int(point[0])+25, int(point[1])+8),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 1)  # ç™½è‰²è¾¹æ¡†

        # ä¸æ·»åŠ å›¾åƒç±»å‹æ ‡ç­¾ï¼Œé¿å…ä¸å¹¶æ’å›¾åƒçš„æ ‡ç­¾é‡å 

        return result_image
            
    def update_result_text(self, text):
        """æ›´æ–°ç»“æœæ˜¾ç¤ºæ–‡æœ¬"""
        # æ£€æŸ¥result_textæ§ä»¶æ˜¯å¦å·²åˆ›å»º
        if hasattr(self, 'result_text') and self.result_text:
            self.result_text.insert(tk.END, text)
            self.result_text.see(tk.END)
            self.root.update_idletasks()
        else:
            # å¦‚æœæ§ä»¶è¿˜æ²¡åˆ›å»ºï¼Œæ‰“å°åˆ°æ§åˆ¶å°
            print(text.strip())

    def calculate_tip_position(self):
        """è®¡ç®—ä¸¤ä¸ªå°–ç«¯ä½ç½®çš„æ¬§å¼è·ç¦»"""
        if self.start_points is None or self.end_points is None:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆæ£€æµ‹ä¸¤å¼ å›¾ç‰‡çš„æ ‡è®°ç‚¹")
            return

        try:
            self.status_var.set("æ­£åœ¨è®¡ç®—ä¸¤ç‚¹é—´è·ç¦»...")
            self.update_result_text("\nğŸ” å¼€å§‹è®¡ç®—èµ·å§‹ç‚¹å’Œç»ˆç‚¹çš„å°–ç«¯ä½ç½®...\n")

            # å™¨æ¢°åæ ‡ç³»ä¸‹çš„5ä¸ªæ ‡è®°ç‚¹åæ ‡ï¼ˆä»tool_tip_calibration.pyä¸­è·å–ï¼‰
            points_3d_tool = np.array([
                [0.0, 0.0, 0.0],      # Aç‚¹ï¼šåŸç‚¹
                [87.5, 0.0, 0.0],     # Bç‚¹ï¼šXè½´ä¸Š
                [33.6, 21.1, 0.0],    # Cç‚¹
                [25.3, -33.6, 0.0],   # Dç‚¹
                [48.9, -57.5, 0.0]    # Eç‚¹
            ], dtype=np.float32)

            # è®¡ç®—èµ·å§‹ç‚¹çš„å°–ç«¯ä½ç½®
            self.update_result_text("ğŸ“ è®¡ç®—èµ·å§‹ç‚¹å°–ç«¯ä½ç½®...\n")
            self.start_tip_position = self.calculate_single_tip_position(
                self.start_points, points_3d_tool, "èµ·å§‹ç‚¹"
            )

            # è®¡ç®—ç»ˆç‚¹çš„å°–ç«¯ä½ç½®
            self.update_result_text("ğŸ¯ è®¡ç®—ç»ˆç‚¹å°–ç«¯ä½ç½®...\n")
            self.end_tip_position = self.calculate_single_tip_position(
                self.end_points, points_3d_tool, "ç»ˆç‚¹"
            )

            if self.start_tip_position is not None and self.end_tip_position is not None:
                # è®¡ç®—æ¬§å¼è·ç¦»
                distance = np.linalg.norm(self.end_tip_position - self.start_tip_position)

                # æ˜¾ç¤ºç»“æœ
                self.update_result_text("\n" + "="*50 + "\n")
                self.update_result_text("ğŸ“ ä¸¤ç‚¹é—´è·ç¦»è®¡ç®—ç»“æœ\n")
                self.update_result_text("="*50 + "\n")
                self.update_result_text(f"ğŸ“ èµ·å§‹ç‚¹å°–ç«¯åæ ‡: [{self.start_tip_position[0]:.3f}, {self.start_tip_position[1]:.3f}, {self.start_tip_position[2]:.3f}] mm\n")
                self.update_result_text(f"ğŸ¯ ç»ˆç‚¹å°–ç«¯åæ ‡:   [{self.end_tip_position[0]:.3f}, {self.end_tip_position[1]:.3f}, {self.end_tip_position[2]:.3f}] mm\n")
                self.update_result_text(f"ğŸ“ ä¸¤ç‚¹é—´æ¬§å¼è·ç¦»: {distance:.3f} mm\n")
                self.update_result_text("="*50 + "\n")

                self.status_var.set(f"âœ… ä¸¤ç‚¹é—´è·ç¦»: {distance:.3f} mm")
            else:
                raise Exception("æ— æ³•è®¡ç®—å°–ç«¯ä½ç½®")

        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"è®¡ç®—è·ç¦»å¤±è´¥: {e}")
            self.status_var.set("è®¡ç®—å¤±è´¥")
            self.update_result_text(f"âŒ è®¡ç®—å¤±è´¥: {e}\n")

    def calculate_single_tip_position(self, detected_points, points_3d_tool, point_type):
        """è®¡ç®—å•ä¸ªå›¾ç‰‡çš„å°–ç«¯ä½ç½®"""
        try:
            # ä½¿ç”¨PnPæ±‚è§£ç›¸æœºå§¿æ€
            success, rvec, tvec = cv2.solvePnP(
                points_3d_tool, detected_points,
                self.camera_matrix, self.dist_coeffs,
                flags=cv2.SOLVEPNP_EPNP
            )

            if not success:
                raise Exception(f"{point_type}PnPæ±‚è§£å¤±è´¥")

            # ä½¿ç”¨LMç²¾åŒ–æé«˜ç²¾åº¦
            rvec_refined, tvec_refined = cv2.solvePnPRefineLM(
                points_3d_tool, detected_points,
                self.camera_matrix, self.dist_coeffs,
                rvec, tvec
            )

            # è®¡ç®—é‡æŠ•å½±è¯¯å·®
            projected_points, _ = cv2.projectPoints(
                points_3d_tool, rvec_refined, tvec_refined,
                self.camera_matrix, self.dist_coeffs
            )
            projected_points = projected_points.reshape(-1, 2)
            individual_errors = np.sqrt(np.sum((projected_points - detected_points)**2, axis=1))
            reprojection_error = np.mean(individual_errors)

            # å°†å™¨æ¢°åæ ‡ç³»ä¸‹çš„å°–ç«¯åæ ‡è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
            R, _ = cv2.Rodrigues(rvec_refined)
            T = tvec_refined.flatten()

            # ä½¿ç”¨æ ‡å®šå¾—åˆ°çš„å™¨æ¢°åæ ‡ç³»ä¸‹çš„å°–ç«¯ä½ç½®
            tip_world_calculated = R @ self.tip_tool + T

            self.update_result_text(f"  {point_type}é‡æŠ•å½±è¯¯å·®: {reprojection_error:.3f} åƒç´ \n")
            self.update_result_text(f"  {point_type}å°–ç«¯åæ ‡: [{tip_world_calculated[0]:.3f}, {tip_world_calculated[1]:.3f}, {tip_world_calculated[2]:.3f}] mm\n")

            return tip_world_calculated

        except Exception as e:
            self.update_result_text(f"âŒ {point_type}è®¡ç®—å¤±è´¥: {e}\n")
            return None

    def analyze_reprojection_error(self, individual_errors, projected_points, detected_points):
        """
        åˆ†æé‡æŠ•å½±è¯¯å·®ï¼Œæ‰¾å‡ºé—®é¢˜ç‚¹

        Args:
            individual_errors: æ¯ä¸ªç‚¹çš„é‡æŠ•å½±è¯¯å·®
            projected_points: æŠ•å½±ç‚¹åæ ‡
            detected_points: æ£€æµ‹ç‚¹åæ ‡
        """
        self.update_result_text("\n=== é‡æŠ•å½±è¯¯å·®è¯¦ç»†åˆ†æ ===\n")

        # æ˜¾ç¤ºæ¯ä¸ªç‚¹çš„è¯¯å·®
        for i, error in enumerate(individual_errors):
            detected = detected_points[i]
            projected = projected_points[i]
            diff_x = projected[0] - detected[0]
            diff_y = projected[1] - detected[1]

            status = "âœ… è‰¯å¥½" if error < 3.0 else "âš ï¸ åå¤§" if error < 5.0 else "âŒ è¿‡å¤§"
            self.update_result_text(f"ç‚¹{i+1}: è¯¯å·®={error:.2f}åƒç´  {status}\n")
            self.update_result_text(f"  æ£€æµ‹åæ ‡: ({detected[0]:.1f}, {detected[1]:.1f})\n")
            self.update_result_text(f"  æŠ•å½±åæ ‡: ({projected[0]:.1f}, {projected[1]:.1f})\n")
            self.update_result_text(f"  åç§»: dx={diff_x:.2f}, dy={diff_y:.2f}\n")

        # æ‰¾å‡ºè¯¯å·®æœ€å¤§çš„ç‚¹
        max_error_idx = np.argmax(individual_errors)
        self.update_result_text(f"\nè¯¯å·®æœ€å¤§çš„ç‚¹: ç‚¹{max_error_idx+1}, è¯¯å·®={individual_errors[max_error_idx]:.2f}åƒç´ \n")

        # æä¾›å¯èƒ½çš„åŸå› å’Œå»ºè®®
        self.update_result_text("\nå¯èƒ½çš„åŸå› :\n")
        if np.max(individual_errors) > 5.0:
            self.update_result_text("1. ç‚¹æ£€æµ‹ä¸å‡†ç¡® - å°è¯•æ”¹è¿›æ£€æµ‹ç®—æ³•æˆ–æ‰‹åŠ¨è°ƒæ•´ç‚¹ä½ç½®\n")
            self.update_result_text("2. ç‚¹åŒ¹é…é”™è¯¯ - æ£€æŸ¥ABCDEç‚¹çš„å¯¹åº”å…³ç³»æ˜¯å¦æ­£ç¡®\n")
            self.update_result_text("3. ç›¸æœºæ ‡å®šä¸å‡†ç¡® - é‡æ–°è¿›è¡Œç›¸æœºæ ‡å®š\n")
            self.update_result_text("4. å·¥å…·æ ‡å®šåæ ‡ä¸å‡†ç¡® - æ£€æŸ¥3Dåæ ‡æ˜¯å¦æ­£ç¡®\n")

    def optimize_pose_estimation(self, points_3d, points_2d, initial_rvec, initial_tvec):
        """
        ä¼˜åŒ–ä½å§¿ä¼°è®¡ï¼Œå°è¯•å‡å°‘é‡æŠ•å½±è¯¯å·®

        Args:
            points_3d: 3Dç‚¹åæ ‡
            points_2d: 2Dç‚¹åæ ‡
            initial_rvec: åˆå§‹æ—‹è½¬å‘é‡
            initial_tvec: åˆå§‹å¹³ç§»å‘é‡

        Returns:
            tuple: (ä¼˜åŒ–åçš„rvec, ä¼˜åŒ–åçš„tvec, ä¼˜åŒ–åçš„è¯¯å·®)
        """
        try:
            # å°è¯•ä¸åŒçš„PnPç®—æ³•
            methods = [
                (cv2.SOLVEPNP_ITERATIVE, "è¿­ä»£æ³•"),
                (cv2.SOLVEPNP_EPNP, "EPnP"),
                (cv2.SOLVEPNP_P3P, "P3P"),
                (cv2.SOLVEPNP_AP3P, "AP3P"),
                (cv2.SOLVEPNP_IPPE, "IPPE"),
                (cv2.SOLVEPNP_IPPE_SQUARE, "IPPE_SQUARE")
            ]

            best_error = float('inf')
            best_rvec = initial_rvec
            best_tvec = initial_tvec
            best_method = "åŸå§‹æ–¹æ³•"

            for method_flag, method_name in methods:
                try:
                    # ä½¿ç”¨ä¸åŒçš„æ–¹æ³•æ±‚è§£PnP
                    success, rvec, tvec = cv2.solvePnP(
                        points_3d, points_2d,
                        self.camera_matrix, self.dist_coeffs,
                        flags=method_flag
                    )

                    if not success:
                        continue

                    # ä½¿ç”¨LMç²¾åŒ–
                    rvec_refined, tvec_refined = cv2.solvePnPRefineLM(
                        points_3d, points_2d,
                        self.camera_matrix, self.dist_coeffs,
                        rvec, tvec
                    )

                    # è®¡ç®—é‡æŠ•å½±è¯¯å·®
                    projected_points, _ = cv2.projectPoints(
                        points_3d, rvec_refined, tvec_refined,
                        self.camera_matrix, self.dist_coeffs
                    )
                    projected_points = projected_points.reshape(-1, 2)

                    error = np.mean(np.sqrt(np.sum((projected_points - points_2d)**2, axis=1)))

                    self.update_result_text(f"  {method_name}: è¯¯å·®={error:.3f}åƒç´ \n")

                    if error < best_error:
                        best_error = error
                        best_rvec = rvec_refined
                        best_tvec = tvec_refined
                        best_method = method_name

                except Exception:
                    continue

            self.update_result_text(f"æœ€ä½³æ–¹æ³•: {best_method}, è¯¯å·®={best_error:.3f}åƒç´ \n")
            return best_rvec, best_tvec, best_error

        except Exception as e:
            self.update_result_text(f"ä¼˜åŒ–å¤±è´¥: {e}\n")
            return initial_rvec, initial_tvec, float('inf')

    def draw_coordinate_system(self, image, rvec, tvec):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶åæ ‡ç³»å’Œå°–ç«¯ä½ç½®"""
        result_image = image.copy()

        # ç»˜åˆ¶æ£€æµ‹åˆ°çš„ç‚¹
        for i, point in enumerate(self.detected_points):
            cv2.circle(result_image, (int(point[0]), int(point[1])), 8, (0, 255, 0), -1)
            cv2.putText(result_image, f"P{i+1}", (int(point[0])+10, int(point[1])),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        # ç»˜åˆ¶å™¨æ¢°åæ ‡ç³»åŸç‚¹ï¼ˆAç‚¹ï¼‰
        origin_3d = np.array([[0.0, 0.0, 0.0]], dtype=np.float32)
        origin_2d, _ = cv2.projectPoints(origin_3d, rvec, tvec, self.camera_matrix, self.dist_coeffs)
        origin_2d = origin_2d.reshape(-1, 2)[0]

        # ç»˜åˆ¶åæ ‡è½´
        axis_length = 50.0
        axes_3d = np.array([
            [0.0, 0.0, 0.0],      # åŸç‚¹
            [axis_length, 0.0, 0.0],  # Xè½´
            [0.0, axis_length, 0.0],  # Yè½´
            [0.0, 0.0, axis_length]   # Zè½´
        ], dtype=np.float32)

        axes_2d, _ = cv2.projectPoints(axes_3d, rvec, tvec, self.camera_matrix, self.dist_coeffs)
        axes_2d = axes_2d.reshape(-1, 2)

        # ç»˜åˆ¶åæ ‡è½´
        origin = tuple(axes_2d[0].astype(int))
        x_axis = tuple(axes_2d[1].astype(int))
        y_axis = tuple(axes_2d[2].astype(int))
        z_axis = tuple(axes_2d[3].astype(int))

        cv2.line(result_image, origin, x_axis, (0, 0, 255), 3)  # Xè½´ï¼šçº¢è‰²
        cv2.line(result_image, origin, y_axis, (0, 255, 0), 3)  # Yè½´ï¼šç»¿è‰²
        cv2.line(result_image, origin, z_axis, (255, 0, 0), 3)  # Zè½´ï¼šè“è‰²

        # æ ‡æ³¨åæ ‡è½´
        cv2.putText(result_image, "X", x_axis, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        cv2.putText(result_image, "Y", y_axis, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        cv2.putText(result_image, "Z", z_axis, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)

        # ç»˜åˆ¶å°–ç«¯ä½ç½®
        tip_3d = np.array([self.tip_tool], dtype=np.float32)
        tip_2d, _ = cv2.projectPoints(tip_3d, rvec, tvec, self.camera_matrix, self.dist_coeffs)
        tip_2d = tip_2d.reshape(-1, 2)[0]

        cv2.circle(result_image, tuple(tip_2d.astype(int)), 12, (255, 255, 0), -1)  # å°–ç«¯ï¼šé»„è‰²
        cv2.putText(result_image, "TIP", (int(tip_2d[0])+15, int(tip_2d[1])),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)

        return result_image

    def run(self):
        """è¿è¡Œç¨‹åº"""
        self.root.mainloop()


if __name__ == "__main__":
    # åˆ›å»ºå¹¶è¿è¡Œäº¤äº’å¼å°–ç«¯è·Ÿè¸ªå™¨
    app = InteractiveTipTracker()
    app.run()
